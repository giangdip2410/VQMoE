#!/bin/bash
echo 'Run training...'
python -u train.py \
    --cuda \
    --data ./data/one-billion-words \
    --dataset lm1b \
    --n_layer 4 \
    --d_model 256 \
    --n_head 8 \
    --d_head 64 \
    --d_inner 512 \
    --dropout 0.1 \
    --dropatt 0.0 \
    --optim adam \
    --lr 0.00035 \
    --warmup_step 0 \
    --max_step 100000 \
    --tgt_len 512 \
    --mem_len 512 \
    --eval_tgt_len 128 \
    --batch_size 11 \
    --multi_gpu \
    --moe --moe-num-expert 16 --moe-top-k 1 \
    --gate_name CustomNaiveGate_Balance_StableMoE \
    --vq_gate \
    --num_embeddings 16 \
    --beta_vq 0.08 \
    --vqtype base \
    --one_gate \
    --contrib_rate 0.05 \
    --load_balance 0.01 \
    --attn_type 2 \
    --mem_len 0 \
    --work_dir Trans-VQMoE-lm1b-V1
